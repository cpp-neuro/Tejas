{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.svm import OneClassSVM as ocs\n",
    "from sklearn.model_selection import train_test_split\n",
    "#import matplotlib.pyplot as plt\n",
    "#import matplotlib.font_manager\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           F4_ALPHA      F7_ALPHA      F8_ALPHA\n",
      "0      1.710770e-11  1.483753e-11  2.359074e-09\n",
      "1      5.847752e-11  1.862107e-11  2.902378e-09\n",
      "2      1.244954e-10  2.542831e-11  3.408178e-09\n",
      "3      1.881736e-10  3.892275e-11  3.956783e-09\n",
      "4      2.119659e-10  6.558095e-11  4.622091e-09\n",
      "5      1.792408e-10  1.172565e-10  5.457625e-09\n",
      "6      1.151778e-10  2.129489e-10  6.496043e-09\n",
      "7      7.733518e-11  3.766075e-10  7.725507e-09\n",
      "8      1.232432e-10  6.289677e-10  9.073904e-09\n",
      "9      2.807579e-10  9.746479e-10  1.043523e-08\n",
      "10     5.400222e-10  1.389084e-09  1.172574e-08\n",
      "11     8.667429e-10  1.812401e-09  1.292959e-08\n",
      "12     1.225093e-09  2.157990e-09  1.409638e-08\n",
      "13     1.597195e-09  2.338595e-09  1.527670e-08\n",
      "14     1.988761e-09  2.301225e-09  1.642441e-08\n",
      "15     2.414378e-09  2.050014e-09  1.732758e-08\n",
      "16     2.864381e-09  1.639525e-09  1.762930e-08\n",
      "17     3.271832e-09  1.147244e-09  1.696810e-08\n",
      "18     3.513175e-09  6.553832e-10  1.519934e-08\n",
      "19     3.462926e-09  2.538601e-10  1.255354e-08\n",
      "20     3.075868e-09  3.773030e-11  9.554972e-09\n",
      "21     2.434283e-09  6.301128e-11  6.723339e-09\n",
      "22     1.714850e-09  2.749986e-10  4.343275e-09\n",
      "23     1.092774e-09  4.988579e-10  2.497981e-09\n",
      "24     6.569200e-10  5.611546e-10  1.207610e-09\n",
      "25     3.974250e-10  4.430637e-10  4.503259e-10\n",
      "26     2.551820e-10  2.795255e-10  1.196500e-10\n",
      "27     1.773094e-10  2.072661e-10  6.955091e-11\n",
      "28     1.394540e-10  2.560474e-10  1.982442e-10\n",
      "29     1.353564e-10  3.729435e-10  4.454511e-10\n",
      "...             ...           ...           ...\n",
      "33270  3.245269e-10  1.710008e-09  2.210038e-11\n",
      "33271  2.305551e-10  1.315392e-09  3.191611e-11\n",
      "33272  1.707576e-10  7.314204e-10  5.890957e-11\n",
      "33273  1.634675e-10  2.597068e-10  8.777346e-11\n",
      "33274  2.034267e-10  5.610763e-11  1.046446e-10\n",
      "33275  2.597118e-10  6.598979e-11  1.065656e-10\n",
      "33276  2.983192e-10  1.539048e-10  9.877546e-11\n",
      "33277  3.079717e-10  2.400844e-10  8.742236e-11\n",
      "33278  2.969084e-10  3.243346e-10  7.438691e-11\n",
      "33279  2.661108e-10  4.442317e-10  5.701454e-11\n",
      "33280  2.019192e-10  6.477024e-10  3.386576e-11\n",
      "33281  1.092656e-10  9.875430e-10  1.225619e-11\n",
      "33282  3.834157e-11  1.496345e-09  6.551200e-12\n",
      "33283  4.624263e-11  2.126280e-09  2.274302e-11\n",
      "33284  1.305158e-10  2.707816e-09  4.685025e-11\n",
      "33285  2.266943e-10  3.013207e-09  5.791202e-11\n",
      "33286  2.708457e-10  2.911756e-09  5.163398e-11\n",
      "33287  2.458875e-10  2.465621e-09  4.143680e-11\n",
      "33288  1.767463e-10  1.866522e-09  3.870126e-11\n",
      "33289  1.028490e-10  1.300351e-09  4.288608e-11\n",
      "33290  5.413573e-11  8.705173e-10  4.861424e-11\n",
      "33291  3.937235e-11  6.012496e-10  5.237073e-11\n",
      "33292  4.950759e-11  4.716736e-10  5.266729e-11\n",
      "33293  6.816457e-11  4.474566e-10  4.985878e-11\n",
      "33294  7.943766e-11  5.061253e-10  4.635354e-11\n",
      "33295  7.419935e-11  6.554276e-10  4.495422e-11\n",
      "33296  5.538813e-11  9.237778e-10  4.724287e-11\n",
      "33297  3.495274e-11  1.303040e-09  5.321600e-11\n",
      "33298  2.288783e-11  1.686273e-09  6.044832e-11\n",
      "33299  1.997027e-11  1.890747e-09  6.384679e-11\n",
      "\n",
      "[33300 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset for alpha\n",
    "path = '/home/tejas/Desktop/Neuro_Data/tf_alpha/'\n",
    "X = pd.concat([pd.read_csv(f, sep = ',') for f in glob.glob(path+'Alyse*.csv')], ignore_index = True)\n",
    "#X = pd.read_csv(\"/home/tejas/Desktop/Neuro_Data/tf_alpha/Alyse_2_2_ALPHA_2019-03-27.csv\", sep = ',')\n",
    "# Declare required columns\n",
    "columns = \"F4_ALPHA F7_ALPHA F8_ALPHA\".split()\n",
    "# Train with relevant data\n",
    "df = pd.DataFrame(X, columns=columns)\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24975, 3)\n",
      "(8325, 3)\n"
     ]
    }
   ],
   "source": [
    "# Training and Testing correct data\n",
    "x_train, x_test = train_test_split(df)\n",
    "\n",
    "print x_train.shape\n",
    "print x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           F4_ALPHA      F7_ALPHA      F8_ALPHA\n",
      "0      1.524070e-09  1.128478e-10  1.504143e-10\n",
      "1      2.159131e-09  2.152690e-10  3.576096e-10\n",
      "2      2.797363e-09  3.782063e-10  7.797030e-10\n",
      "3      3.440770e-09  6.164683e-10  1.528264e-09\n",
      "4      4.175988e-09  9.314331e-10  2.666193e-09\n",
      "5      5.086710e-09  1.293973e-09  4.121418e-09\n",
      "6      6.116732e-09  1.633800e-09  5.631909e-09\n",
      "7      7.014453e-09  1.852075e-09  6.789572e-09\n",
      "8      7.427144e-09  1.861027e-09  7.199639e-09\n",
      "9      7.086719e-09  1.632573e-09  6.683574e-09\n",
      "10     5.963948e-09  1.224159e-09  5.392211e-09\n",
      "11     4.296590e-09  7.589104e-10  3.734164e-09\n",
      "12     2.493074e-09  3.717884e-10  2.170417e-09\n",
      "13     9.920110e-10  1.596941e-10  1.029469e-09\n",
      "14     1.404181e-10  1.594834e-10  4.379497e-10\n",
      "15     9.578875e-11  3.481674e-10  3.433229e-10\n",
      "16     7.564956e-10  6.518118e-10  5.674810e-10\n",
      "17     1.775961e-09  9.650313e-10  8.693926e-10\n",
      "18     2.711791e-09  1.192099e-09  1.030984e-09\n",
      "19     3.252563e-09  1.299042e-09  9.586609e-10\n",
      "20     3.374269e-09  1.336879e-09  7.428612e-10\n",
      "21     3.319662e-09  1.409053e-09  6.137567e-10\n",
      "22     3.414401e-09  1.602550e-09  7.897239e-10\n",
      "23     3.839707e-09  1.928178e-09  1.301049e-09\n",
      "24     4.512112e-09  2.305313e-09  1.927037e-09\n",
      "25     5.138272e-09  2.597746e-09  2.323827e-09\n",
      "26     5.390068e-09  2.677303e-09  2.258302e-09\n",
      "27     5.085547e-09  2.480207e-09  1.763610e-09\n",
      "28     4.272399e-09  2.032702e-09  1.094729e-09\n",
      "29     3.176348e-09  1.439802e-09  5.312156e-10\n",
      "...             ...           ...           ...\n",
      "33270  1.198727e-10  1.055959e-10  9.739593e-11\n",
      "33271  6.416901e-11  1.168403e-10  4.301682e-11\n",
      "33272  2.219181e-11  1.199323e-10  4.057683e-11\n",
      "33273  2.661799e-12  1.309897e-10  6.777349e-11\n",
      "33274  1.042699e-12  1.845830e-10  9.186451e-11\n",
      "33275  8.714460e-12  3.099313e-10  1.035390e-10\n",
      "33276  1.967473e-11  5.050983e-10  1.166985e-10\n",
      "33277  3.159396e-11  7.300840e-10  1.456696e-10\n",
      "33278  4.331278e-11  9.262543e-10  1.855389e-10\n",
      "33279  5.250353e-11  1.047030e-09  2.141180e-10\n",
      "33280  5.643336e-11  1.075604e-09  2.123000e-10\n",
      "33281  5.426163e-11  1.019672e-09  1.791719e-10\n",
      "33282  4.700435e-11  8.964880e-10  1.275651e-10\n",
      "33283  3.564658e-11  7.258660e-10  7.194995e-11\n",
      "33284  2.142578e-11  5.316680e-10  2.520503e-11\n",
      "33285  1.022623e-11  3.415236e-10  5.666191e-12\n",
      "33286  1.818626e-11  1.819675e-10  4.458968e-11\n",
      "33287  7.038269e-11  7.291831e-11  1.800033e-10\n",
      "33288  1.848645e-10  2.223657e-11  4.277936e-10\n",
      "33289  3.488537e-10  2.358739e-11  7.445217e-10\n",
      "33290  5.120004e-10  6.547296e-11  1.021117e-09\n",
      "33291  6.135981e-10  1.491802e-10  1.131760e-09\n",
      "33292  6.259124e-10  3.034747e-10  1.013805e-09\n",
      "33293  5.750779e-10  5.924153e-10  7.257934e-10\n",
      "33294  5.183128e-10  1.116420e-09  4.479028e-10\n",
      "33295  4.952833e-10  1.984874e-09  4.249265e-10\n",
      "33296  4.983142e-10  3.224539e-09  8.592358e-10\n",
      "33297  4.883009e-10  4.641499e-09  1.758696e-09\n",
      "33298  4.348817e-10  5.771852e-09  2.820646e-09\n",
      "33299  3.398751e-10  6.086530e-09  3.530646e-09\n",
      "\n",
      "[133200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Getting outliers\n",
    "O1 = pd.concat([pd.read_csv(f, sep = ',') for f in glob.glob(path+'Keaton*.csv')], ignore_index = True)\n",
    "O2 = pd.concat([pd.read_csv(f, sep = ',') for f in glob.glob(path+'Morty*.csv')], ignore_index = True)\n",
    "O3 = pd.concat([pd.read_csv(f, sep = ',') for f in glob.glob(path+'Jay*.csv')], ignore_index = True)\n",
    "O4 = pd.concat([pd.read_csv(f, sep = ',') for f in glob.glob(path+'Richard*.csv')], ignore_index = True)\n",
    "\n",
    "frames = [O1, O2, O3, O4]\n",
    "outliers = pd.concat(frames)\n",
    "out = pd.DataFrame(outliers, columns=columns)\n",
    "print out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ocs(nu=0.1, kernel=\"poly\", gamma=0.1)\n",
    "#clf = ocs(nu=0.1, kernel=\"linear\", gamma=0.1)\n",
    "#clf = ocs(nu=0.1, kernel=\"rbf\", gamma=0.1)\n",
    "#clf = ocs(nu=0.1, kernel=\"sigmoid\", gamma=0.1)\n",
    "ocsvm = clf.fit(x_train)\n",
    "y_pred_train = clf.predict(x_train)\n",
    "y_pred_test = clf.predict(x_test)\n",
    "y_pred_outliers = clf.predict(out)\n",
    "n_error_train = y_pred_train[y_pred_train == -1].size\n",
    "n_error_test = y_pred_test[y_pred_test == -1].size\n",
    "n_error_outliers = y_pred_outliers[y_pred_outliers == 1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "[ 1.  1.  1. ...,  1.  1.  1.]\n",
      "0\n",
      "0\n",
      "133200\n"
     ]
    }
   ],
   "source": [
    "print y_pred_train\n",
    "print y_pred_test\n",
    "print y_pred_outliers\n",
    "print n_error_train\n",
    "print n_error_test\n",
    "print n_error_outliers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
